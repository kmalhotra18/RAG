{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1PY1Jisu64eSX9J7G6abSb6_ZWgNhbvKh",
      "authorship_tag": "ABX9TyNDh4PzUJq9AwxVXU1AKrBi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmalhotra18/RAG/blob/main/Expert_Knowledge_Worker_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expert Knowledge Worker**\n",
        "\n",
        "1.   A question answering agent that is an expert knowledge worker\n",
        "2.   To be used by employees of Insurellm, an Insurance Tech company\n",
        "3.   The agent needs to be accurate and the solution should be low cost.\n"
      ],
      "metadata": {
        "id": "CTywumO0qjUC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6qSL7cwpuCJ"
      },
      "outputs": [],
      "source": [
        "!pip install -q OpenAI\n",
        "!pip install -q google-generativeai\n",
        "!pip install -q python-dotenv\n",
        "!pip install -q anthropic\n",
        "!pip install -q gradio\n",
        "!pip install -q langchain-community # Install the langchain-community package"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "\n",
        "import os\n",
        "import glob\n",
        "from dotenv import load_dotenv\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "p2ad5yxepxmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imports for langchain\n",
        "\n",
        "from langchain.document_loaders import DirectoryLoader, TextLoader                # DirectoryLoader loads in entire folder, TextLoader is to load individual text files\n",
        "from langchain.text_splitter import CharacterTextSplitter                         # Divides document into chunks of characters"
      ],
      "metadata": {
        "id": "TuZZSsAdp9vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# price is a factor for our company, so we're going to use a low cost model\n",
        "\n",
        "MODEL = \"gpt-4o-mini\"\n",
        "db_name = \"vector_db\""
      ],
      "metadata": {
        "id": "O1miFdxVqtTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load environment variables in a file called .env\n",
        "\n",
        "load_dotenv(override=True)\n",
        "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')"
      ],
      "metadata": {
        "id": "OQL74T5Eqwt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in documents using LangChain's loaders\n",
        "# Take everything in all the sub-folders of our knowledgebase\n",
        "#folders = glob.glob(\"knowledge-base/*\")\n",
        "\n",
        "folders = glob.glob(\"/content/drive/MyDrive/Llms/llm_engineering/week5/knowledge-base/*\")             # Get list of folders in knowledge base\n",
        "\n",
        "text_loader_kwargs = {'encoding': 'utf-8'}\n",
        "# If that doesn't work, some Windows users might need to uncomment the next line instead\n",
        "# text_loader_kwargs={'autodetect_encoding': True}\n",
        "\n",
        "documents = []\n",
        "for folder in folders:                                                                                # For each folder, get types of documents\n",
        "    doc_type = os.path.basename(folder)\n",
        "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
        "    folder_docs = loader.load()                                                                       # To bring in all documents\n",
        "    for doc in folder_docs:                                                                           # For each document, add metadata as doc type, and add to list called 'documents'\n",
        "        doc.metadata[\"doc_type\"] = doc_type\n",
        "        documents.append(doc)"
      ],
      "metadata": {
        "id": "4iFNQywmqwrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(documents)"
      ],
      "metadata": {
        "id": "1X9c7zRhqwoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents[24]"
      ],
      "metadata": {
        "id": "N8xqiWNcjps7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take the document, divide each doc into chunks of characters\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)                     # Divide each document in roughly 1000 chunk size. Chunk overlap - some content of doc thats common in differnet chunks.\n",
        "chunks = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "NR2z8mZ1jpqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks)"
      ],
      "metadata": {
        "id": "FSD-ujJfjpna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks[6]"
      ],
      "metadata": {
        "id": "kUE8JkvGjpk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See doc types across all the chunks\n",
        "\n",
        "doc_types = set(chunk.metadata['doc_type'] for chunk in chunks)\n",
        "print(f\"Document types found: {', '.join(doc_types)}\")"
      ],
      "metadata": {
        "id": "CBv9mGlkjuXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Look through each chunk, see which has CEO in chunks (as an example)\n",
        "\n",
        "for chunk in chunks:\n",
        "    if 'CEO' in chunk.page_content:\n",
        "        print(chunk)\n",
        "        print(\"_________\")"
      ],
      "metadata": {
        "id": "X1QPqwbcjuVK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}